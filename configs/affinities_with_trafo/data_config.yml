# Specify the names of the datasets
dataset_names:
  - '1'
  - '2'
  - '3'
  - '4'

# Specify how the data needs to be sliced before feeding to the network.
# We use a 3D sliding window over the dataset to extract patches, which
# are then fed to the network as batches.
slicing_config:
  # Sliding window size
  window_size:
    '1': [160, 160, 160]
    '2': [160, 160, 160]
    '3': [160, 160, 160]
    '4': [160, 160, 160]
  # Sliding window stride
  stride:
    '1': [90, 90, 90]
    '2': [90, 90, 90]
    '3': [90, 90, 90]
    '4': [90, 90, 90]
  # Data slice to iterate over.
  # data_slice:
  #   A: '0:65, :, :'
  #   B: '0:65, :, :'
  #   C: '0:65, :, :'
    
# Specify paths to volumes
volume_config:
  # Raw data
  raw:
    path:
      '1': '/g/kreshuk/data/fib25_blocks/raw/raw_block1.h5'
      '2': '/g/kreshuk/data/fib25_blocks/raw/raw_block2.h5'
      '3': '/g/kreshuk/data/fib25_blocks/raw/raw_block3.h5'
      '4': '/g/kreshuk/data/fib25_blocks/raw/raw_block4.h5'
    path_in_h5_dataset:
      '1': 'data'
      '2': 'data'
      '3': 'data'
      '4': 'data'
    dtype: float32
  # Segmentation
  segmentation:
    path:
      '1': '/g/kreshuk/data/fib25_blocks/gt/gt_block1.h5'
      '2': '/g/kreshuk/data/fib25_blocks/gt/gt_block2.h5'
      '3': '/g/kreshuk/data/fib25_blocks/gt/gt_block3.h5'
      '4': '/g/kreshuk/data/fib25_blocks/gt/gt_block4.h5'
    path_in_h5_dataset:
      '1': 'data'
      '2': 'data'
      '3': 'data'
      '4': 'data'
    dtype: float32
    affinity_config:
        offsets:
                 - [-1, 0, 0]
                 - [0, -1, 0]
                 - [0, 0, -1]
                 - [-4, 0, 0]
                 - [0, -4, 0]
                 - [0, 0, -4]
                 - [-8, 0, 0]
                 - [0, -8, 0]
                 - [0, 0, -8]
                 - [-16, 0, 0]
                 - [0, -16, 0]
                 - [0, 0, -16]
        retain_mask: True
        ignore_label: 0


# Configuration for the master dataset.
master_config:
  # We might need order 0 interpolation if we have segmentation in there somewhere.
  elastic_transform:
    alpha: 2000.
    sigma: 50.
    order: 0


# Specify configuration for the loader
loader_config:
  # Number of processes to use for loading data. Set to (say) 10 if you wish to
  # use 10 CPU cores, or to 0 if you wish to use the same process for training and
  # data-loading (generally not recommended).
  batch_size: 1
  num_workers: 6
  drop_last: True
  pin_memory: True
  shuffle: True
